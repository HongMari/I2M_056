# new056.py (ë©€í‹°ìŠ¤í…Œì´ì§€: í›„ë³´ ìƒì„± â†’ ê²€ì¦/ìŠ¤ëƒ…ë°± â†’ í•©ì˜)

import os
import re
import json
import html
import urllib.parse
from dataclasses import dataclass
from typing import Optional, Dict, Any, List
from pathlib import Path

import requests
import streamlit as st
from bs4 import BeautifulSoup

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Streamlit ê¸°ë³¸ ì„¤ì • (ì œì¼ ìœ„ì—ì„œ ë”± 1ë²ˆë§Œ!)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="ISBN â†’ KDC ì¶”ì²œ(ì„¸ëª©ê¹Œì§€)",
    page_icon="ğŸ“š",
    layout="centered"
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìƒìˆ˜/ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_MODEL = "gpt-4o-mini"
ALADIN_LOOKUP_URL = "https://www.aladin.co.kr/ttb/api/ItemLookUp.aspx"
ALADIN_SEARCH_URL = "https://www.aladin.co.kr/search/wsearchresult.aspx"
OPENAI_CHAT_COMPLETIONS = "https://api.openai.com/v1/chat/completions"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (compatible; KDCFetcher/1.1; +https://example.local)"
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ secrets.toml ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ fallback â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _get_secret(*path, default=""):
    """st.secretsì—ì„œ ì¤‘ì²© ê²½ë¡œë¥¼ ì•ˆì „í•˜ê²Œ êº¼ë‚´ëŠ” ìœ í‹¸."""
    try:
        v = st.secrets
        for p in path:
            v = v[p]
        return v
    except Exception:
        return default

# [api_keys] ë˜ëŠ” ìµœìƒìœ„ í‚¤ ë‘˜ ë‹¤ í—ˆìš©
OPENAI_API_KEY = (
    _get_secret("api_keys", "openai_key")
    or _get_secret("OPENAI_API_KEY")
    or os.environ.get("OPENAI_API_KEY", "")
)
ALADIN_TTBKEY = (
    _get_secret("api_keys", "aladin_key")
    or _get_secret("ALADIN_TTB_KEY")
    or os.environ.get("ALADIN_TTBKEY", "")
)

MODEL = DEFAULT_MODEL

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë””ë²„ê·¸ íŒ¨ë„ â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.expander("í™˜ê²½ì„¤ì • ë””ë²„ê·¸", expanded=True):
    st.write("ğŸ“ ì•± í´ë”:", Path(__file__).resolve().parent.as_posix())
    st.write("ğŸ” secrets.toml ì¡´ì¬?:", (Path(__file__).resolve().parent / ".streamlit" / "secrets.toml").exists())
    try:
        st.write("ğŸ”‘ st.secrets í‚¤ë“¤:", list(st.secrets.keys()))
        st.write("api_keys ë‚´ìš©:", dict(st.secrets.get("api_keys", {})))
    except Exception:
        st.write("st.secrets ì ‘ê·¼ ì‹¤íŒ¨(ë¡œì»¬ ì‹¤í–‰ì¼ ìˆ˜ ìˆìŒ)")
    st.write("âœ… OPENAI( api_keys/openai_key or OPENAI_API_KEY ) ë¡œë“œë¨?:", bool(OPENAI_API_KEY))
    st.write("âœ… ALADIN( api_keys/aladin_key or ALADIN_TTB_KEY ) ë¡œë“œë¨?:", bool(ALADIN_TTBKEY))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë°ì´í„° êµ¬ì¡° â”€â”€â”€â”€â”€â”€â”€â”€â”€
@dataclass
class BookInfo:
    title: str = ""
    author: str = ""
    pub_date: str = ""
    publisher: str = ""
    isbn13: str = ""
    category: str = ""
    description: str = ""
    toc: str = ""
    extra: Dict[str, Any] = None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€
def clean_text(s: Optional[str]) -> str:
    if not s:
        return ""
    s = html.unescape(s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def strip_tags(html_text: str) -> str:
    return re.sub(r"<[^>]+>", " ", html_text)

def normalize_code(code: str) -> str:
    """
    KDC ì½”ë“œ ì„œì‹ ì •ê·œí™”: ddd ë˜ëŠ” ddd.d (ì„¸ ìë¦¬ + ì„ íƒ ì†Œìˆ˜ì  1~n)
    5 -> 005, 813.70 -> 813.7
    """
    if not code:
        return ""
    m = re.match(r"^\s*(\d{1,3})(\.\d+)?\s*$", code)
    if not m:
        return ""
    head = m.group(1).zfill(3)
    tail = m.group(2) or ""
    # ì†Œìˆ˜ì ì€ ë¶ˆí•„ìš”í•œ 0 ì •ë¦¬ (ì˜ˆ: .70 -> .7)
    if tail and re.match(r"^\.\d+$", tail):
        tail = re.sub(r"0+$", "", tail)
        if tail == ".":  # ëª¨ë‘ 0ì´ì—ˆë‹¤ë©´ ì œê±°
            tail = ""
    return head + tail

def short(text: str, n: int = 600) -> str:
    if not text:
        return ""
    return (text[:n] + "â€¦") if len(text) > n else text

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1) ì•Œë¼ë”˜ API ìš°ì„  â”€â”€â”€â”€â”€â”€â”€â”€â”€
def aladin_lookup_by_api(isbn13: str, ttbkey: str) -> Optional[BookInfo]:
    if not ttbkey:
        return None
    params = {
        "ttbkey": ttbkey,
        "itemIdType": "ISBN13",
        "ItemId": isbn13,
        "output": "js",
        "Version": "20131101",
        "OptResult": "authors,categoryName,fulldescription,toc,packaging,ratings"
    }
    try:
        r = requests.get(ALADIN_LOOKUP_URL, params=params, headers=HEADERS, timeout=15)
        r.raise_for_status()
        data = r.json()
        items = data.get("item", [])
        if not items:
            st.info("ì•Œë¼ë”˜ API(ItemLookUp)ì—ì„œ ê²°ê³¼ ì—†ìŒ â†’ ìŠ¤í¬ë ˆì´í•‘ ë°±ì—… ì‹œë„")
            return None
        it = items[0]
        return BookInfo(
            title=clean_text(it.get("title")),
            author=clean_text(it.get("author")),
            pub_date=clean_text(it.get("pubDate")),
            publisher=clean_text(it.get("publisher")),
            isbn13=clean_text(it.get("isbn13")) or isbn13,
            category=clean_text(it.get("categoryName")),
            description=clean_text(it.get("fulldescription")) or clean_text(it.get("description")),
            toc=clean_text(it.get("toc")),
            extra=it,
        )
    except Exception as e:
        st.info(f"ì•Œë¼ë”˜ API í˜¸ì¶œ ì˜ˆì™¸ â†’ {e} / ìŠ¤í¬ë ˆì´í•‘ ë°±ì—… ì‹œë„")
        return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2) ì•Œë¼ë”˜ ì›¹ ìŠ¤í¬ë ˆì´í•‘(ë°±ì—…) â”€â”€â”€â”€â”€â”€â”€â”€â”€
def aladin_lookup_by_web(isbn13: str) -> Optional[BookInfo]:
    try:
        params = {"SearchTarget": "Book", "SearchWord": f"isbn:{isbn13}"}
        sr = requests.get(ALADIN_SEARCH_URL, params=params, headers=HEADERS, timeout=15)
        sr.raise_for_status()

        soup = BeautifulSoup(sr.text, "html.parser")

        # 1) ëŒ€í‘œ ì¹´ë“œ ë§í¬
        link_tag = soup.select_one("a.bo3")
        item_url = None
        if link_tag and link_tag.get("href"):
            item_url = urllib.parse.urljoin("https://www.aladin.co.kr", link_tag["href"])

        # 2) ë°±ì—…: ì •ê·œì‹
        if not item_url:
            m = re.search(r'href=[\'"](/shop/wproduct\.aspx\?ItemId=\d+[^\'"]*)[\'"]', sr.text, re.I)
            if m:
                item_url = urllib.parse.urljoin("https://www.aladin.co.kr", html.unescape(m.group(1)))

        # 3) ì²« ì¹´ë“œ ë‚´ë¶€ ì•„ë¬´ ë§í¬
        if not item_url:
            first_card = soup.select_one(".ss_book_box, .ss_book_list")
            if first_card:
                a = first_card.find("a", href=True)
                if a:
                    item_url = urllib.parse.urljoin("https://www.aladin.co.kr", a["href"])

        if not item_url:
            st.warning("ì•Œë¼ë”˜ ê²€ìƒ‰ í˜ì´ì§€ì—ì„œ ìƒí’ˆ ë§í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            with st.expander("ë””ë²„ê·¸: ê²€ìƒ‰ í˜ì´ì§€ HTML ì¼ë¶€"):
                st.code(sr.text[:2000])
            return None

        pr = requests.get(item_url, headers=HEADERS, timeout=15)
        pr.raise_for_status()
        psoup = BeautifulSoup(pr.text, "html.parser")

        og_title = psoup.select_one('meta[property="og:title"]')
        og_desc  = psoup.select_one('meta[property="og:description"]')
        title = clean_text(og_title["content"]) if og_title and og_title.has_attr("content") else ""
        desc  = clean_text(og_desc["content"]) if og_desc and og_desc.has_attr("content") else ""

        body_text = clean_text(psoup.get_text(" "))[:4000]
        description = desc or body_text

        author = ""
        publisher = ""
        pub_date = ""
        cat_text = ""

        info_box = psoup.select_one("#Ere_prod_allwrap, #Ere_prod_mconts_wrap, #Ere_prod_titlewrap")
        if info_box:
            text = clean_text(info_box.get_text(" "))
            m_author = re.search(r"(ì €ì|ì§€ì€ì´)\s*:\s*([^\|Â·/]+)", text)
            m_publisher = re.search(r"(ì¶œíŒì‚¬)\s*:\s*([^\|Â·/]+)", text)
            m_pubdate = re.search(r"(ì¶œê°„ì¼|ì¶œíŒì¼)\s*:\s*([0-9]{4}\.[0-9]{1,2}\.[0-9]{1,2})", text)
            if m_author:   author   = clean_text(m_author.group(2))
            if m_publisher: publisher = clean_text(m_publisher.group(2))
            if m_pubdate:  pub_date = clean_text(m_pubdate.group(2))

        crumbs = psoup.select(".location, .path, .breadcrumb")
        if crumbs:
            cat_text = clean_text(" > ".join(c.get_text(" ") for c in crumbs))

        with st.expander("ë””ë²„ê·¸: ìŠ¤í¬ë ˆì´í•‘ ì§„ì… URL / íŒŒì‹± ê²°ê³¼"):
            st.write({"item_url": item_url, "title": title})

        return BookInfo(
            title=title,
            description=description,
            isbn13=isbn13,
            author=author,
            publisher=publisher,
            pub_date=pub_date,
            category=cat_text
        )
    except Exception as e:
        st.error(f"ì›¹ ìŠ¤í¬ë ˆì´í•‘ ì˜ˆì™¸: {e}")
        return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3) LLM: ê´€ì ë³„ í›„ë³´ 3ê°œ(JSON) ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _ask_llm_candidates(payload: Dict[str, Any], api_key: str, model: str) -> List[Dict[str, Any]]:
    """
    ì…ë ¥ payload(ê´€ì ë³„: title/description/toc ë“±)ë¥¼ ì£¼ê³ ,
    í›„ë³´ 3ê°œë¥¼ JSON ë°°ì—´ë¡œ ë°›ëŠ”ë‹¤.
    ê° ì›ì†Œ: {code, level, confidence, evidence_terms}
    """
    if not api_key:
        raise RuntimeError("OPENAI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°” ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì…ë ¥í•˜ì„¸ìš”.")

    sys_prompt = (
        "ë„ˆëŠ” í•œêµ­ ì‹­ì§„ë¶„ë¥˜(KDC) ì „ë¬¸ê°€ë‹¤. "
        "ì…ë ¥ëœ ë„ì„œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì¥ íƒ€ë‹¹í•œ KDC â€˜ì„¸ëª©ê¹Œì§€â€™ í›„ë³´ 3ê°œë¥¼ JSON ë°°ì—´ë¡œë§Œ ì¶œë ¥í•˜ë¼. "
        "ê° í›„ë³´ëŠ” {\"code\":\"813.7\",\"level\":\"ì„¸ëª©\",\"confidence\":0.82,"
        "\"evidence_terms\":[\"ì†Œì„¤\",\"ì²­ì†Œë…„\",\"ë‹¨í¸\"]} í˜•ì‹ì„ ë”°ë¥¸ë‹¤. "
        "ê·œì¹™: (1) codeëŠ” ë°˜ë“œì‹œ 000â€“999 ë²”ìœ„ì˜ ì„¸ ìë¦¬ + ì„ íƒ ì†Œìˆ˜ì  í˜•ì‹(ì˜ˆ: 005, 813.7), "
        "(2) ì„¤ëª…, ë¬¸ì¥, ì£¼ì„, ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€, ì˜¤ì§ JSON ë°°ì—´ë§Œ ì¶œë ¥, "
        "(3) ì í•©í•˜ì§€ ì•Šì€ ìƒìœ„ë¥˜ëŠ” í”¼í•˜ê³  ê°€ëŠ¥í•œ í•œ ì„¸ëª©ê¹Œì§€ ì œì‹œ, "
        "(4) ë¬¸í•™/ì•„ë™/IT/ì˜í•™ ë“± ëª…ë°±í•œ ì‹ í˜¸ê°€ ìˆìœ¼ë©´ ê·¸ ë¶„ì•¼ì˜ ì„¸ëª©ì„ ìš°ì„  ì œì‹œ."
    )

    user_prompt = (
        "ë„ì„œ ì •ë³´(JSON):\n"
        f"{json.dumps(payload, ensure_ascii=False)}\n\n"
        "ë°˜ë“œì‹œ JSON ë°°ì—´ë§Œ ì¶œë ¥:"
    )

    try:
        resp = requests.post(
            OPENAI_CHAT_COMPLETIONS,
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
            },
            json={
                "model": model,
                "messages": [
                    {"role": "system", "content": sys_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                "temperature": 0.3,
                "max_tokens": 300,
            },
            timeout=40,
        )
        resp.raise_for_status()
        data = resp.json()
        txt = (data["choices"][0]["message"]["content"] or "").strip()

        # JSONë§Œ ì¶”ì¶œ(í˜¹ì‹œ ì•ë’¤ì— ë­”ê°€ ë¶™ìœ¼ë©´ ë°©ì–´)
        # ë°°ì—´ ì‹œì‘/ëì„ íƒìƒ‰
        start = txt.find("[")
        end = txt.rfind("]")
        if start == -1 or end == -1 or end < start:
            return []
        arr_text = txt[start:end+1]
        arr = json.loads(arr_text)
        if isinstance(arr, list):
            # í•„ë“œ ë°©ì–´ì  ì •ê·œí™”
            out = []
            for x in arr:
                if not isinstance(x, dict):
                    continue
                code = normalize_code(str(x.get("code", "")))
                if not code:
                    continue
                level = str(x.get("level", "")).strip() or "ì„¸ëª©"
                conf = float(x.get("confidence", 0.0))
                ev = x.get("evidence_terms", [])
                if not isinstance(ev, list):
                    ev = []
                out.append({"code": code, "level": level, "confidence": conf, "evidence_terms": ev})
            return out
        return []
    except Exception as e:
        st.error(f"LLM í›„ë³´ ìƒì„± í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return []

def perspective_payload(book: BookInfo, view: str) -> Dict[str, Any]:
    base = {"isbn13": book.isbn13, "category": book.category}
    if view == "title":
        base["title"] = book.title
        # ì‹œë¦¬ì¦ˆ/ë¶€ì œ ë“± í™•ì¥ ê°€ëŠ¥
    elif view == "description":
        base["description"] = book.description
    elif view == "toc":
        base["toc"] = book.toc
    else:
        base["title"] = book.title
    # ì €ì/ì¶œíŒì‚¬/ë°œí–‰ë…„ë„ëŠ” ëª¨ë“  ê´€ì ì— ê°€ë³ê²Œ í¬í•¨(ë³´ì¡° ì‹ í˜¸)
    base["author"] = book.author
    base["publisher"] = book.publisher
    base["pub_date"] = book.pub_date
    return base

def get_candidates_multi_view(book: BookInfo, api_key: str, model: str) -> List[Dict[str, Any]]:
    all_cands: List[Dict[str, Any]] = []
    for view in ["title", "description", "toc"]:
        payload = perspective_payload(book, view=view)
        cands = _ask_llm_candidates(payload, api_key, model)
        # ê´€ì  ì •ë³´ ë³´ì¡´(ë””ë²„ê·¸ìš©)
        for c in cands:
            c["_view"] = view
        all_cands.extend(cands)
    return all_cands

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4) ê°„ë‹¨í•œ ê²€ì¦/ë£°/ìŠ¤ëƒ…ë°± â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ì¤€ë¹„ë˜ë©´ ì‹¤ì œ KDC ì„¸ëª© ì½”ë“œì…‹ìœ¼ë¡œ êµì²´í•˜ì„¸ìš”.
# ë‹¹ì¥ì€ 3ìë¦¬ë§Œ ê¸°ë³¸ ìœ íš¨ë¡œ ë³´ê³ , ì„¸ëª©ì€ normalizeë§Œ.
VALID_3DIGITS = {f"{i:03d}" for i in range(0, 1000)}

def snap_to_valid(code: str) -> str:
    """
    ì„¸ëª©ì´ ìœ íš¨ì½”ë“œì…‹ì— ì—†ë‹¤ë©´ ìƒìœ„(ì†Œìˆ˜ì  ì œê±°, 3ìë¦¬)ë¡œ ìŠ¤ëƒ…ë°±.
    ì§€ê¸ˆì€ 3ìë¦¬ë§Œ ìœ íš¨ë¡œ ê°€ì •.
    """
    c = normalize_code(code)
    if not c:
        return ""
    if "." in c:
        head3 = c.split(".")[0]
        # ì„¸ëª© ìœ íš¨ì…‹ ì•„ì§ ì—†ìœ¼ë¯€ë¡œ ì¼ë‹¨ 3ìë¦¬ë¡œ ìŠ¤ëƒ… (head3ëŠ” ë°˜ë“œì‹œ 3ìë¦¬)
        return head3
    # 3ìë¦¬
    return c if c[:3] in VALID_3DIGITS else ""

def rule_weight(code: str, book: BookInfo) -> float:
    """
    ì•Œë¼ë”˜ ì¹´í…Œê³ ë¦¬/ì„¤ëª… í‚¤ì›Œë“œë¡œ ê°„ë‹¨ ê°€ì¤‘ì¹˜.
    ë¶„ì•¼ ë¶ˆì¼ì¹˜ ì‹œ ê°ì , ì¼ì¹˜ ì‹œ ê°€ì .
    """
    cat = (book.category or "").lower()
    t = (book.title or "").lower()
    desc = (book.description or "").lower()

    w = 1.0
    # ë¬¸í•™ ê³„ì—´ â†’ 8ë¥˜ ì„ í˜¸
    if any(k in (cat + t + desc) for k in ["ì†Œì„¤", "ë¬¸í•™", "ì—ì„¸ì´", "ì‹œ", "í¬ê³¡"]):
        if code.startswith("8"): w += 0.3
        else: w -= 0.5

    # ì•„ë™/ì²­ì†Œë…„ ì‹ í˜¸ â†’ 813.7 ë“± ì„¸ëª© ì„ í˜¸(ì¼ë‹¨ 8ë¥˜ ê°€ì )
    if any(k in (cat + desc) for k in ["ì•„ë™", "ì–´ë¦°ì´", "ë™í™”", "ê·¸ë¦¼ì±…", "ì²­ì†Œë…„"]):
        if code.startswith("8"): w += 0.2

    # ì»´í“¨í„°/IT â†’ 004/005/006 ë“±
    if any(k in (cat + desc) for k in ["ì»´í“¨í„°", "it", "ì¸ê³µì§€ëŠ¥", "í”„ë¡œê·¸ë˜ë°", "ë°ì´í„°"]):
        if code.startswith(("004", "005", "006")): w += 0.3
        else: w -= 0.3

    # ì˜í•™/ê°„í˜¸/ì•½í•™ â†’ 51x/52x (ê°„ë‹¨ ì‹ í˜¸)
    if any(k in (cat + desc) for k in ["ì˜í•™", "ê±´ê°•", "ì•½í•™", "ê°„í˜¸", "ì„ìƒ"]):
        if code.startswith(("510", "511", "512", "513", "514", "520", "521", "522")):
            w += 0.25
        else:
            w -= 0.15

    # ì—­ì‚¬/ì§€ë¦¬ ì‹ í˜¸
    if any(k in (cat + desc) for k in ["ì—­ì‚¬", "ê³ ëŒ€", "ê·¼í˜„ëŒ€", "ì§€ë¦¬", "ì—¬í–‰ê¸°"]):
        if code.startswith(("9", "910", "920", "930", "940")): w += 0.2

    return w

def pick_final_code(candidates: List[Dict[str, Any]], book: BookInfo) -> Optional[str]:
    """
    í›„ë³´ë“¤ì„ ìŠ¤ëƒ…ë°±+ê°€ì¤‘ì¹˜ë¡œ ì ìˆ˜í™”í•˜ì—¬ ìµœì¢… 1ê°œ ì„ íƒ.
    """
    scores: Dict[str, float] = {}
    if not candidates:
        return None

    for c in candidates:
        raw = c.get("code", "")
        snapped = snap_to_valid(raw)
        if not snapped:
            continue
        conf = float(c.get("confidence", 0.0))
        w = rule_weight(snapped, book)
        # ê´€ì  ê°€ì¤‘ì¹˜: ëª©ì°¨ > ì„¤ëª… > ì œëª©
        view = c.get("_view", "")
        if view == "toc":        view_w = 1.15
        elif view == "description": view_w = 1.05
        else:                    view_w = 1.0
        scores[snapped] = scores.get(snapped, 0.0) + conf * w * view_w

    if not scores:
        return None
    best = max(scores.items(), key=lambda x: x[1])[0]
    return normalize_code(best)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5) íŒŒì´í”„ë¼ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_kdc_from_isbn_hybrid(isbn13: str, ttbkey: Optional[str], openai_key: str, model: str) -> Dict[str, Any]:
    """
    ë°˜í™˜: {"final": "813.7" ë˜ëŠ” "813", "candidates": [...], "book": BookInfo}
    """
    info = aladin_lookup_by_api(isbn13, ttbkey) if ttbkey else None
    if not info:
        info = aladin_lookup_by_web(isbn13)
    if not info:
        return {"final": None, "candidates": [], "book": None}

    cands = get_candidates_multi_view(info, api_key=openai_key, model=model)
    final_code = pick_final_code(cands, info)

    return {"final": final_code, "candidates": cands, "book": info}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ UI â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ğŸ“š ISBN â†’ KDC ì¶”ì²œ (ì„¸ëª©ê¹Œì§€, í•˜ì´ë¸Œë¦¬ë“œ)")
st.caption("ì•Œë¼ë”˜(API/ì›¹)ìœ¼ë¡œ ì„œì§€ ìˆ˜ì§‘ â†’ ê´€ì  3ë¶„í•  í›„ë³´ ìƒì„± â†’ ê·œì¹™/ìŠ¤ëƒ…ë°± ê²€ì¦ â†’ í•©ì˜ë¡œ ìµœì¢… ì„ íƒ")

isbn = st.text_input("ISBN-13 ì…ë ¥", placeholder="ì˜ˆ: 9791193904565").strip()
go = st.button("ë¶„ë¥˜ê¸°í˜¸ ì¶”ì²œ")

if go:
    if not isbn:
        st.warning("ISBNì„ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        with st.spinner("ì•Œë¼ë”˜ ì •ë³´ ìˆ˜ì§‘ â†’ í›„ë³´ ìƒì„± â†’ ê²€ì¦/í•©ì˜ ì¤‘â€¦"):
            out = get_kdc_from_isbn_hybrid(
                isbn13=isbn,
                ttbkey=ALADIN_TTBKEY,
                openai_key=OPENAI_API_KEY,
                model=MODEL,
            )

        info: BookInfo = out.get("book")
        cands: List[Dict[str, Any]] = out.get("candidates", [])
        final_code = out.get("final")

        st.subheader("ê²°ê³¼")
        if final_code:
            st.markdown(f"### âœ… ìµœì¢… KDC ì¶”ì²œ: **`{final_code}`**")
            st.caption("â€» ì„¸ëª© ìœ íš¨ì…‹ì´ ì¤€ë¹„ë˜ê¸° ì „ê¹Œì§€ëŠ” 3ìë¦¬ë¡œ ìŠ¤ëƒ…ë°±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì˜ˆ: 813.7 â†’ 813)")
        else:
            st.error("ë¶„ë¥˜ê¸°í˜¸ ì¶”ì²œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ISBN/í‚¤ë¥¼ í™•ì¸í•˜ê±°ë‚˜, ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")

        # ì…ë ¥ ì •ë³´ ë””ë²„ê·¸
        with st.expander("LLM ì…ë ¥ ì •ë³´(í™•ì¸ìš©)"):
            if info:
                st.json({
                    "title": info.title,
                    "author": info.author,
                    "publisher": info.publisher,
                    "pub_date": info.pub_date,
                    "isbn13": info.isbn13,
                    "category": info.category,
                    "description": short(info.description, 600),
                    "toc": short(info.toc, 600),
                })
            else:
                st.write("ë„ì„œ ì •ë³´ ì—†ìŒ")

        # í›„ë³´/ì ìˆ˜ ë””ë²„ê·¸
        with st.expander("í›„ë³´ ìƒì„¸(JSON)"):
            st.json(cands)

        st.info(
            "íŒ: ì •í™•ë„ë¥¼ ë” ì˜¬ë¦¬ë ¤ë©´ (1) ëª©ì°¨ë¥¼ ë” ì˜ ìˆ˜ì§‘, (2) ìê´€ì˜ ë¼ë²¨ í™•ì‹¤í•œ ì˜ˆì‹œ 10~20ê¶Œì„ í”„ë¡¬í”„íŠ¸ few-shotìœ¼ë¡œ ì¶”ê°€, "
            "(3) KDC ì„¸ëª© ìœ íš¨ì…‹ì„ ì ì§„ì ìœ¼ë¡œ í™•ì¥í•´ ìŠ¤ëƒ…ë°± ëŒ€ì‹  ì‹¤ì½”ë“œ ê²€ì¦ì„ ìˆ˜í–‰í•˜ì„¸ìš”."
        )
