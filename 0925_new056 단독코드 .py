# new056.py (EA_ADD_CODE â†’ 'ë¥˜' ì•µì»¤ í†µí•©)
# ê¸°ì¡´ UI ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë©°, 1ë‹¨ê³„ë¡œ êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ OpenAPI EA_ADD_CODEì˜ ë’¤ 3ìë¦¬ì—ì„œ
# ë°±ì˜ ìë¦¬(ì²« ìë¦¬)ë¥¼ KDC 'ë¥˜'ë¡œ ê³ ì •(ì•µì»¤)í•œ ë’¤ â†’ 2ë‹¨ê³„ ì•Œë¼ë”˜+LLMìœ¼ë¡œ ê°•Â·ëª©Â·ì„¸ëª© ë³´ì •

import os
import re
import json
import html
import urllib.parse
from dataclasses import dataclass
from typing import Optional, Dict, Any
from bs4 import BeautifulSoup
from pathlib import Path

import requests
import streamlit as st

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Streamlit ê¸°ë³¸ ì„¤ì • (ì œì¼ ìœ„ì—ì„œ ë”± 1ë²ˆë§Œ!)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="ISBN â†’ KDC ì¶”ì²œ",
    page_icon="ğŸ“š",
    layout="centered"
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìƒìˆ˜/ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_MODEL = "gpt-4o-mini"
ALADIN_LOOKUP_URL = "https://www.aladin.co.kr/ttb/api/ItemLookUp.aspx"
ALADIN_SEARCH_URL = "https://www.aladin.co.kr/search/wsearchresult.aspx"
OPENAI_CHAT_COMPLETIONS = "https://api.openai.com/v1/chat/completions"
NLK_SEARCH_API = "https://www.nl.go.kr/NL/search/openApi/search.do"
NLK_SEOJI_API  = "https://www.nl.go.kr/seoji/SearchApi.do"  # ISBN ì„œì§€ API (docs[].EA_ADD_CODE)


with st.expander("í™˜ê²½ì„¤ì • ë””ë²„ê·¸", expanded=True):
    st.write("ğŸ“ ì•± í´ë”:", Path(__file__).resolve().parent.as_posix())
    st.write("ğŸ” secrets.toml ì¡´ì¬?:", (Path(__file__).resolve().parent / ".streamlit" / "secrets.toml").exists())
    st.write("ğŸ”‘ st.secrets í‚¤ë“¤:", list(st.secrets.keys()))
    st.write("api_keys ë‚´ìš©:", dict(st.secrets.get("api_keys", {})))
    st.write("âœ… openai_key ë¡œë“œë¨?:", bool(st.secrets.get("api_keys", {}).get("openai_key")))
    st.write("âœ… aladin_key ë¡œë“œë¨?:", bool(st.secrets.get("api_keys", {}).get("aladin_key")))
    st.write("âœ… nlk_key ë¡œë“œë¨?:", bool(st.secrets.get("api_keys", {}).get("nlk_key")))

HEADERS = {
    "User-Agent": "Mozilla/5.0 (compatible; KDCFetcher/1.0; +https://example.local)"
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ secrets.toml ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ fallback â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _get_secret(*path, default=""):
    """st.secretsì—ì„œ ì¤‘ì²© ê²½ë¡œë¥¼ ì•ˆì „í•˜ê²Œ êº¼ë‚´ëŠ” ìœ í‹¸."""
    try:
        v = st.secrets
        for p in path:
            v = v[p]
        return v
    except Exception:
        return default

# ì§€ê¸ˆ ì‚¬ìš©í•˜ëŠ” secrets.toml êµ¬ì¡°ì— ë§ì¶¤ ([api_keys].openai_key / aladin_key / nlk_key)
OPENAI_API_KEY = (
    _get_secret("api_keys", "openai_key") 
    or os.environ.get("OPENAI_API_KEY", "")
)

ALADIN_TTBKEY = (
    _get_secret("api_keys", "aladin_key") 
    or os.environ.get("ALADIN_TTBKEY", "")
)

NLK_API_KEY = (
    _get_secret("api_keys", "nlk_key")
    or os.environ.get("NLK_API_KEY", "")
)

MODEL = DEFAULT_MODEL

@dataclass
class BookInfo:
    title: str = ""
    author: str = ""
    pub_date: str = ""
    publisher: str = ""
    isbn13: str = ""
    category: str = ""
    description: str = ""
    toc: str = ""
    extra: Dict[str, Any] = None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€

def clean_text(s: Optional[str]) -> str:
    if not s:
        return ""
    s = html.unescape(s)
    s = re.sub(r"\s+", " ", s).strip()
    return s


def first_match_number(text: str) -> Optional[str]:
    """KDC ìˆ«ìë§Œ ì¶”ì¶œ: 0~999 ë˜ëŠ” ì†Œìˆ˜ì  í¬í•¨(ì˜ˆ: 813.7)"""
    if not text:
        return None
    m = re.search(r"\b([0-9]{1,3}(?:\.[0-9]+)?)\b", text)
    return m.group(1) if m else None


def first_or_empty(lst):
    return lst[0] if lst else ""


def strip_tags(html_text: str) -> str:
    return re.sub(r"<[^>]+>", " ", html_text)


def normalize_isbn13(isbn: str) -> str:
    s = re.sub(r"[^0-9Xx]", "", isbn or "")
    return s[-13:] if len(s) >= 13 else s

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0) NLK EA_ADD_CODE ì¡°íšŒ (ë¥˜ ì•µì»¤ ê³ ì •) â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_ea_add_code_last3(isbn13: str, key: str) -> Optional[str]:
    """
    EA_ADD_CODEì˜ ë’¤ 3ìë¦¬ ë°˜í™˜.
    1ì°¨: ì„œì§€(ISBN) API /seoji/SearchApi.do â†’ docs[0].EA_ADD_CODE
    2ì°¨: ì¼ë°˜ê²€ìƒ‰ /NL/search/openApi/search.do â†’ result.recordList[0].EA_ADD_CODE
    """
    if not key:
        st.info("NLK_API_KEYê°€ ì—†ì–´ EA_ADD_CODE ì¡°íšŒë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return None

    # ---------- 1) ì„œì§€(ISBN) API ---------- #
    try:
        p1 = {
            "cert_key": key,         # ì„œì§€ APIëŠ” cert_key ì‚¬ìš©
            "result_style": "json",
            "page_no": 1,
            "page_size": 5,
            "isbn": isbn13,
        }
        r1 = requests.get(NLK_SEOJI_API, params=p1, headers=HEADERS, timeout=10)
        r1.raise_for_status()
        d1 = r1.json() if r1.headers.get("Content-Type","").lower().startswith("application/json") else json.loads(r1.text)

        docs = d1.get("docs")
        if isinstance(docs, list) and docs:
            d0 = docs[0] if isinstance(docs[0], dict) else {}
            ea = d0.get("EA_ADD_CODE") or d0.get("ea_add_code")
            if ea:
                m = re.search(r"(\d{3})$", str(ea))
                if m:
                    last3 = m.group(1)
                    st.success(f"(ì„œì§€API) EA_ADD_CODE: {ea} â†’ ë’¤ 3ìë¦¬={last3}")
                    return last3
        else:
            st.info("ì„œì§€API ì‘ë‹µì— docsê°€ ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìŒ â†’ ì¼ë°˜ê²€ìƒ‰ ë°±ì—…")
    except Exception as e:
        st.info(f"ì„œì§€API ì‹¤íŒ¨ â†’ ì¼ë°˜ê²€ìƒ‰ ë°±ì—…: {e}")

    # ---------- 2) ì¼ë°˜ê²€ìƒ‰ API(ë°±ì—…) ---------- #
    try:
        p2 = {
            "key": key,              # ì¼ë°˜ê²€ìƒ‰ì€ key ì‚¬ìš©
            "srchTarget": "total",
            "kwd": isbn13,
            "pageNum": 1,
            "pageSize": 1,
            "apiType": "json",
        }
        r2 = requests.get(NLK_SEARCH_API, params=p2, headers=HEADERS, timeout=10)
        r2.raise_for_status()
        d2 = r2.json() if r2.headers.get("Content-Type","").lower().startswith("application/json") else json.loads(r2.text)

        result = d2.get("result")
        if isinstance(result, list):
            result = result[0] if result else {}
        recs = None
        if isinstance(result, dict):
            recs = result.get("recordList") or result.get("recordlist") or result.get("records") or result.get("record")
        if isinstance(recs, dict):
            recs = [recs]
        if isinstance(recs, list) and recs:
            rec0 = recs[0]
            if isinstance(rec0, list) and rec0:
                rec0 = rec0[0]
            if isinstance(rec0, dict):
                ea = rec0.get("EA_ADD_CODE") or rec0.get("ea_add_code")
                if ea:
                    m = re.search(r"(\d{3})$", str(ea))
                    if m:
                        last3 = m.group(1)
                        st.success(f"(ì¼ë°˜ê²€ìƒ‰) EA_ADD_CODE: {ea} â†’ ë’¤ 3ìë¦¬={last3}")
                        return last3

        st.warning("NLK SearchApi EA_ADD_CODE ì¡°íšŒ ì‹¤íŒ¨: ì‘ë‹µ êµ¬ì¡° ë¯¸ì¼ì¹˜")
        return None
    except Exception as e:
        st.warning(f"NLK SearchApi EA_ADD_CODE ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1) ì•Œë¼ë”˜ API ìš°ì„  â”€â”€â”€â”€â”€â”€â”€â”€â”€

def aladin_lookup_by_api(isbn13: str, ttbkey: str) -> Optional[BookInfo]:
    if not ttbkey:
        return None
    params = {
        "ttbkey": ttbkey,
        "itemIdType": "ISBN13",
        "ItemId": isbn13,
        "output": "js",
        "Version": "20131101",
        "OptResult": "authors,categoryName,fulldescription,toc,packaging,ratings"
    }
    try:
        r = requests.get(ALADIN_LOOKUP_URL, params=params, headers=HEADERS, timeout=15)
        r.raise_for_status()
        data = r.json()
        items = data.get("item", [])
        if not items:
            st.info("ì•Œë¼ë”˜ API(ItemLookUp)ì—ì„œ ê²°ê³¼ ì—†ìŒ â†’ ìŠ¤í¬ë ˆì´í•‘ ë°±ì—… ì‹œë„")
            return None
        it = items[0]
        return BookInfo(
            title=clean_text(it.get("title")),
            author=clean_text(it.get("author")),
            pub_date=clean_text(it.get("pubDate")),
            publisher=clean_text(it.get("publisher")),
            isbn13=clean_text(it.get("isbn13")) or isbn13,
            category=clean_text(it.get("categoryName")),
            description=clean_text(it.get("fulldescription")) or clean_text(it.get("description")),
            toc=clean_text(it.get("toc")),
            extra=it,
        )
    except Exception as e:
        st.info(f"ì•Œë¼ë”˜ API í˜¸ì¶œ ì˜ˆì™¸ â†’ {e} / ìŠ¤í¬ë ˆì´í•‘ ë°±ì—… ì‹œë„")
        return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2) ì•Œë¼ë”˜ ì›¹ ìŠ¤í¬ë ˆì´í•‘(ë°±ì—…) â”€â”€â”€â”€â”€â”€â”€â”€â”€

def aladin_lookup_by_web(isbn13: str) -> Optional[BookInfo]:
    try:
        params = {"SearchTarget": "Book", "SearchWord": f"isbn:{isbn13}"}
        sr = requests.get(ALADIN_SEARCH_URL, params=params, headers=HEADERS, timeout=15)
        sr.raise_for_status()

        soup = BeautifulSoup(sr.text, "html.parser")

        link_tag = soup.select_one("a.bo3")
        item_url = None
        if link_tag and link_tag.get("href"):
            item_url = urllib.parse.urljoin("https://www.aladin.co.kr", link_tag["href"])
        if not item_url:
            m = re.search(r'href=[\'\"](/shop/wproduct\.aspx\?ItemId=\d+[^\'\"]*)[\'\"]', sr.text, re.I)
            if m:
                item_url = urllib.parse.urljoin("https://www.aladin.co.kr", html.unescape(m.group(1)))
        if not item_url:
            first_card = soup.select_one(".ss_book_box, .ss_book_list")
            if first_card:
                a = first_card.find("a", href=True)
                if a:
                    item_url = urllib.parse.urljoin("https://www.aladin.co.kr", a["href"])

        if not item_url:
            st.warning("ì•Œë¼ë”˜ ê²€ìƒ‰ í˜ì´ì§€ì—ì„œ ìƒí’ˆ ë§í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            with st.expander("ë””ë²„ê·¸: ê²€ìƒ‰ í˜ì´ì§€ HTML ì¼ë¶€"):
                st.code(sr.text[:2000])
            return None

        pr = requests.get(item_url, headers=HEADERS, timeout=15)
        pr.raise_for_status()
        psoup = BeautifulSoup(pr.text, "html.parser")

        og_title = psoup.select_one('meta[property="og:title"]')
        og_desc  = psoup.select_one('meta[property="og:description"]')
        title = clean_text(og_title["content"]) if og_title and og_title.has_attr("content") else ""
        desc  = clean_text(og_desc["content"]) if og_desc and og_desc.has_attr("content") else ""

        body_text = clean_text(psoup.get_text(" "))[:4000]
        description = desc or body_text

        author = ""
        publisher = ""
        pub_date = ""
        cat_text = ""

        info_box = psoup.select_one("#Ere_prod_allwrap, #Ere_prod_mconts_wrap, #Ere_prod_titlewrap")
        if info_box:
            text = clean_text(info_box.get_text(" "))
            m_author = re.search(r"(ì €ì|ì§€ì€ì´)\s*:\s*([^\|Â·/]+)", text)
            m_publisher = re.search(r"(ì¶œíŒì‚¬)\s*:\s*([^\|Â·/]+)", text)
            m_pubdate = re.search(r"(ì¶œê°„ì¼|ì¶œíŒì¼)\s*:\s*([0-9]{4}\.[0-9]{1,2}\.[0-9]{1,2})", text)
            if m_author:   author   = clean_text(m_author.group(2))
            if m_publisher: publisher = clean_text(m_publisher.group(2))
            if m_pubdate:  pub_date = clean_text(m_pubdate.group(2))

        crumbs = psoup.select(".location, .path, .breadcrumb")
        if crumbs:
            cat_text = clean_text(" > ".join(c.get_text(" ") for c in crumbs))

        with st.expander("ë””ë²„ê·¸: ìŠ¤í¬ë ˆì´í•‘ ì§„ì… URL / íŒŒì‹± ê²°ê³¼"):
            st.write({"item_url": item_url, "title": title})
        
        return BookInfo(
            title=title,
            description=description,
            isbn13=isbn13,
            author=author,
            publisher=publisher,
            pub_date=pub_date,
            category=cat_text
        )
    except Exception as e:
        st.error(f"ì›¹ ìŠ¤í¬ë ˆì´í•‘ ì˜ˆì™¸: {e}")
        return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3) ì±—Gì—ê²Œ 'KDC ìˆ«ìë§Œ' ìš”ì²­ (ë¥˜ ì•µì»¤ ê³ ì • ì¡°ê±´ í¬í•¨) â”€â”€â”€â”€â”€â”€â”€â”€â”€

def ask_llm_for_kdc(book: BookInfo, api_key: str, model: str = DEFAULT_MODEL, ryu_anchor: Optional[str] = None) -> Optional[str]:
    if not api_key:
        raise RuntimeError("OPENAI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°” ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì…ë ¥í•˜ì„¸ìš”.")

    # ë¥˜(ë°±ì˜ ìë¦¬) ê³ ì • ì¡°ê±´ì„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ëª…ì‹œ
    anchor_clause = ""
    if ryu_anchor and ryu_anchor.isdigit():
        anchor_clause = (
            f" ë°˜ë“œì‹œ ë°±ì˜ ìë¦¬ëŠ” {ryu_anchor} ì—¬ì•¼ í•œë‹¤. ì˜ˆ: {ryu_anchor}00, {ryu_anchor}13, {ryu_anchor}91, {ryu_anchor}13.7 ë“±. "
            "ë°±ì˜ ìë¦¬ê°€ ë‹¤ë¥´ë©´ ì˜¤ë‹µì´ë‹¤."
        )

    sys_prompt = (
        "ë„ˆëŠ” í•œêµ­ ì‹­ì§„ë¶„ë¥˜(KDC) ì „ë¬¸ê°€ë‹¤. "
        "ì•„ë˜ ë„ì„œ ì •ë³´ë¥¼ ë³´ê³  KDC ë¶„ë¥˜ê¸°í˜¸ë¥¼ 'ìˆ«ìë§Œ' ì¶œë ¥í•´ë¼. "
        "í˜•ì‹ ì˜ˆì‹œ: 813.7 / 325.1 / 005 / 181 ë“±. "
        "ì„¤ëª…, ì ‘ë‘/ì ‘ë¯¸ í…ìŠ¤íŠ¸, ê¸°íƒ€ ë¬¸ìëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆë¼." + anchor_clause
    )
    payload = {
        "title": book.title,
        "author": book.author,
        "publisher": book.publisher,
        "pub_date": book.pub_date,
        "isbn13": book.isbn13,
        "category": book.category,
        "description": book.description,
        "toc": book.toc,
    }
    user_prompt = (
        "ë„ì„œ ì •ë³´(JSON):\n"
        f"{json.dumps(payload, ensure_ascii=False, indent=2)}\n\n"
        "KDC ìˆ«ìë§Œ ì¶œë ¥:"
    )

    try:
        resp = requests.post(
            OPENAI_CHAT_COMPLETIONS,
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
            },
            json={
                "model": model,
                "messages": [
                    {"role": "system", "content": sys_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                "temperature": 0.0,
                "max_tokens": 12,
            },
            timeout=30,
        )
        resp.raise_for_status()
        data = resp.json()
        text = (data["choices"][0]["message"]["content"] or "").strip()
        return first_match_number(text)
    except Exception as e:
        st.error(f"LLM í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4) íŒŒì´í”„ë¼ì¸ (EA_ADD_CODE â†’ ë¥˜ ì•µì»¤ â†’ ì•Œë¼ë”˜ â†’ LLM) â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_kdc_from_isbn(isbn13: str, ttbkey: Optional[str], openai_key: str, model: str) -> Dict[str, Optional[str]]:
    # 0) ë¥˜ ì•µì»¤
    last3 = get_ea_add_code_last3(isbn13, NLK_API_KEY)
    ryu = last3[0] if last3 else None

    # 1) ì•Œë¼ë”˜ ê¸°ë°˜ ë„ì„œì •ë³´ í™•ë³´
    info = aladin_lookup_by_api(isbn13, ttbkey) if ttbkey else None
    if not info:
        info = aladin_lookup_by_web(isbn13)
    if not info:
        st.warning("ì•Œë¼ë”˜ì—ì„œ ë„ì„œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return {"code": None, "ryu": ryu, "ea_add_last3": last3}

    # 2) LLMì—ê²Œ KDC ìˆ«ìë§Œ ìš”ì²­(ë¥˜ ì•µì»¤ ì¡°ê±´ í¬í•¨)
    code = ask_llm_for_kdc(info, api_key=openai_key, model=model, ryu_anchor=ryu)

    # 3) ì•µì»¤ ê²€ì¦/ë³´ì •: LLMì´ ì‹¤ìˆ˜ë¡œ ë‹¤ë¥¸ ë¥˜ë¥¼ ë‚´ë©´ ê°•ì œ ë³´ì •
    if code and ryu and code[0].isdigit() and code[0] != ryu:
        st.warning(f"LLM ê²°ê³¼({code})ê°€ ì•µì»¤ ë¥˜({ryu})ì™€ ë¶ˆì¼ì¹˜ â†’ ë¥˜ ê°•ì œ ê³ ì •")
        code = ryu + code[1:]

    # 4) ë””ë²„ê·¸: LLM ì…ë ¥ ì •ë³´ í‘œì‹œ
    with st.expander("LLM ì…ë ¥ ì •ë³´(í™•ì¸ìš©)"):
        st.json({
            "title": info.title,
            "author": info.author,
            "publisher": info.publisher,
            "pub_date": info.pub_date,
            "isbn13": info.isbn13,
            "category": info.category,
            "description": (info.description[:600] + "â€¦") if info.description and len(info.description) > 600 else info.description,
            "toc": info.toc,
            "ryu_anchor": ryu,
            "ea_add_last3": last3,
        })
    return {"code": code, "ryu": ryu, "ea_add_last3": last3}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ UI â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.title("ğŸ“š ISBN â†’ KDC ì¶”ì²œ (EA ì•µì»¤ + ì•Œë¼ë”˜ + ì±—G)")
st.caption("â‘  êµ­ë¦½ì¤‘ì•™ë„ì„œê´€ EA_ADD_CODEë¡œ 'ë¥˜' ê³ ì • â†’ â‘¡ ì•Œë¼ë”˜ì—ì„œ ì„œì§€ì •ë³´ ìˆ˜ì§‘ â†’ â‘¢ ì±—Gë¡œ KDC ìˆ«ì ë„ì¶œ")

isbn = st.text_input("ISBN-13 ì…ë ¥", placeholder="ì˜ˆ: 9791193904565").strip()
go = st.button("ë¶„ë¥˜ê¸°í˜¸ ì¶”ì²œ")

if go:
    if not isbn:
        st.warning("ISBNì„ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        norm = normalize_isbn13(isbn)
        if not norm or len(norm) != 13:
            st.info("ISBN-13 í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        with st.spinner("EA ì•µì»¤ í™•ì¸ â†’ ì•Œë¼ë”˜ ì •ë³´ ìˆ˜ì§‘ â†’ ì±—G íŒë‹¨â€¦"):
            result = get_kdc_from_isbn(
                isbn13=norm or isbn,
                ttbkey=ALADIN_TTBKEY,
                openai_key=OPENAI_API_KEY,
                model=MODEL,
            )

        st.subheader("ê²°ê³¼")
        if result.get("ea_add_last3"):
            st.markdown(f"- **EA_ADD_CODE ë’¤ 3ìë¦¬**: `{result['ea_add_last3']}`")
            st.markdown(f"- **ë¥˜(ì•µì»¤)**: `{result['ryu']}`")
        else:
            st.markdown("- **EA_ADD_CODE**: ì¡°íšŒ ì‹¤íŒ¨(ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰)")
        code = result.get("code")
        if code:
            st.markdown(f"### âœ… ì¶”ì²œ KDC: **`{code}`**")
            st.caption("â€» LLM ì¶œë ¥ì€ 'ìˆ«ìë§Œ'ìœ¼ë¡œ ì œí•œë˜ë©°, ë¥˜(ë°±ì˜ ìë¦¬)ëŠ” EA ì•µì»¤ì— ë§ì¶° ê³ ì •ë©ë‹ˆë‹¤.")
        else:
            st.error("ë¶„ë¥˜ê¸°í˜¸ ì¶”ì²œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ISBN/í‚¤ë¥¼ í™•ì¸í•˜ê±°ë‚˜, ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ê·¼ê±°/ìˆœìœ„Â·ì¡°í•© í‘œì‹œ â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("---")
st.markdown("#### ğŸ” ì¶”ì²œ ê·¼ê±° (ìˆœìœ„Â·ì¡°í•©)")
ryu = result.get("ryu")
ranking = result.get("ranking") or []
sig = result.get("signals") or {}


with st.expander("ê·¼ê±° ìš”ì•½", expanded=True):
st.markdown(
f"- **EA ì•µì»¤(ë¥˜)**: `{ryu or '-'}'`")
st.markdown(
f"- **ì‹ í˜¸ ì¡°í•©**: ì œëª©/ì¹´í…Œê³ ë¦¬/ì €ì/ì¶œíŒì‚¬ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ LLMì´ ì‚°ì¶œí•œ í›„ë³´ì˜ confidenceë¥¼ ê³„ì‚°")
st.markdown(
f"- **ì‚¬ìš©ëœ ë©”íƒ€ë°ì´í„°**: ì œëª©='{sig.get('title','')}', ì¹´í…Œê³ ë¦¬='{sig.get('category','')}', ì €ì='{sig.get('author','')}', ì¶œíŒì‚¬='{sig.get('publisher','')}'")


# í›„ë³´ í…Œì´ë¸”
if ranking:
import pandas as _pd
rows = []
for i, c in enumerate(ranking, start=1):
code_i = c.get("code")
conf = c.get("confidence")
try:
conf_pct = f"{float(conf)*100:.1f}%" if conf is not None else ""
except Exception:
conf_pct = ""
rows.append({
"ìˆœìœ„": i,
"KDC í›„ë³´": code_i,
"ì‹ ë¢°ë„": conf_pct,
"ê·¼ê±° í‚¤ì›Œë“œ": ", ".join(c.get("evidence_terms", [])[:6]),
"ì°¸ì¡° ë·°": c.get("_view", "")
})
df = _pd.DataFrame(rows)
try:
from caas_jupyter_tools import display_dataframe_to_user as _disp
_disp("ì¶”ì²œ ê·¼ê±°(ìˆœìœ„í‘œ)", df)
except Exception:
st.dataframe(df, use_container_width=True)
else:
st.info("ê·¼ê±° í‘œì‹œëŠ” ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (LLM JSON ì‹¤íŒ¨ ë˜ëŠ” ì‹ í˜¸ ë¶€ì¡±)")


