# new056.py

import os
import re
import json
import html
import urllib.parse
from dataclasses import dataclass
from typing import Optional, Dict, Any
from bs4 import BeautifulSoup
from pathlib import Path

import requests
import streamlit as st

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
...
)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìƒìˆ˜/ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_MODEL = "gpt-4o-mini"
ALADIN_LOOKUP_URL = "https://www.aladin.co.kr/ttb/api/ItemLookUp.aspx"
ALADIN_SEARCH_URL = "https://www.aladin.co.kr/search/wsearchresult.aspx"
OPENAI_CHAT_COMPLETIONS = "https://api.openai.com/v1/chat/completions"

with st.expander("í™˜ê²½ì„¤ì • ë””ë²„ê·¸", expanded=True):
    from pathlib import Path
    st.write("ğŸ“ ì•± í´ë”:", Path(__file__).resolve().parent.as_posix())
    st.write("ğŸ” secrets.toml ì¡´ì¬?:", (Path(__file__).resolve().parent / ".streamlit" / "secrets.toml").exists())
    st.write("ğŸ”‘ st.secrets í‚¤ë“¤:", list(st.secrets.keys()))
    st.write("api_keys ë‚´ìš©:", dict(st.secrets.get("api_keys", {})))
    st.write("âœ… openai_key ë¡œë“œë¨?:", bool(st.secrets.get("api_keys", {}).get("openai_key")))
    st.write("âœ… aladin_key ë¡œë“œë¨?:", bool(st.secrets.get("api_keys", {}).get("aladin_key")))



HEADERS = {
    "User-Agent": "Mozilla/5.0 (compatible; KDCFetcher/1.0; +https://example.local)"
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ secrets.toml ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ fallback â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _get_secret(*path, default=""):
    """st.secretsì—ì„œ ì¤‘ì²© ê²½ë¡œë¥¼ ì•ˆì „í•˜ê²Œ êº¼ë‚´ëŠ” ìœ í‹¸."""
    try:
        v = st.secrets
        for p in path:
            v = v[p]
...
    author: str = ""
    pub_date: str = ""
    publisher: str = ""
    isbn13: str = ""
    category: str = ""
    description: str = ""
    toc: str = ""
    extra: Dict[str, Any] = None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€
def clean_text(s: Optional[str]) -> str:
    if not s:
        return ""
    s = html.unescape(s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def first_match_number(text: str) -> Optional[str]:
    """KDC ìˆ«ìë§Œ ì¶”ì¶œ: 0~999 ë˜ëŠ” ì†Œìˆ˜ì  í¬í•¨(ì˜ˆ: 813.7)"""
    if not text:
        return None
    m = re.search(r"\b([0-9]{1,3}(?:\.[0-9]+)?)\b", text)
    return m.group(1) if m else None

def first_or_empty(lst):
    return lst[0] if lst else ""

def strip_tags(html_text: str) -> str:
    return re.sub(r"<[^>]+>", " ", html_text)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ NLK(Open API) â€” EA_ADD_CODE ì¡°íšŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€
def nlk_fetch_ea_add_code(isbn13: str, api_key: Optional[str]) -> Optional[str]:
    """
    NLK Open API ì¼ë°˜ê²€ìƒ‰ìœ¼ë¡œ ISBNì„ ì¡°íšŒí•˜ì—¬ EA_ADD_CODEë¥¼ ì–»ëŠ”ë‹¤.
    ë°˜í™˜: 'ë’¤ 3ìë¦¬' ë¶„ë¥˜ì½”ë“œ(ì˜ˆ: '813') ë˜ëŠ” None
    """
    if not api_key:
        return None
    try:
        url = "https://www.nl.go.kr/NL/search/openApi/search.do"
        params = {
            "key": api_key,
            "srchTarget": "total",
            "kwd": isbn13,
            "pageNum": 1,
            "pageSize": 1,
            "apiType": "json",
        }
        r = requests.get(url, params=params, timeout=10)
        r.raise_for_status()
        ctype = r.headers.get("Content-Type", "").lower()
        data = r.json() if "json" in ctype else {}

        # ê²°ê³¼ êµ¬ì¡°ëŠ” ìœ ë™ì ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê´€ìš©ì ìœ¼ë¡œ íƒìƒ‰
        item = None
        for cand in ("result", "RESULT", "item", "ITEM", "docs", "DOCS", "channel", "CHANNEL"):
            v = data.get(cand) if isinstance(data, dict) else None
            if isinstance(v, list) and v:
                item = v[0]
                break
            if isinstance(v, dict) and v:
                item = v
                break
        if not item:
            return None

        # EA_ADD_CODE í›„ë³´ í‚¤
        ea_val = None
        for k in ("ea_add_code", "EA_ADD_CODE", "eaAddCode", "EA_ADDCD", "EA_ADD"):
            if k in item:
                ea_val = str(item[k])
                break
        if not ea_val:
            return None

        # ë’¤ 3ìë¦¬ë§Œ ì¶”ì¶œ
        m = re.search(r"(\d{3})\s*$", ea_val)
        return m.group(1) if m else None

    except Exception as e:
        st.error(f"NLK SearchApi EA_ADD_CODE ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None


# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç™¾ä½(ë¥˜) ê°•ì œ ë³´ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€
def enforce_anchor_ryu(kdc: str, anchor: Optional[str]) -> str:
    """
    kdc = '816.7' ê°™ì€ ë¬¸ìì—´, anchor = '8' ê°™ì€ í•œ ìë¦¬(ç™¾ä½).
    anchorê°€ ìˆê³  kdcì˜ ë°±ìœ„ê°€ ë‹¤ë¥´ë©´ ê°•ì œë¡œ anchorë¡œ êµì²´.
    """
    if not (kdc and anchor and anchor.isdigit() and len(anchor) == 1):
        return kdc
    norm = re.sub(r"\s+", "", kdc)
    m = re.match(r"(\d)(\d{2}(?:\.\d+)?)$", norm)
    if not m:
        m2 = re.match(r"(\d)(\d{0,2}(?:\.\d+)?)$", norm)
        if not m2:
            return kdc
        return anchor + m2.group(2)
    if m.group(1) == anchor:
        return kdc
    return anchor + m.group(2)

...

def aladin_lookup_by_web(isbn13: str) -> Optional[BookInfo]:
    try:
        # ê²€ìƒ‰ URL (Book íƒ€ê²Ÿ ìš°ì„ )
        params = {"SearchTarget": "Book", "SearchWord": f"isbn:{isbn13}"}
        sr = requests.get(ALADIN_SEARCH_URL, params=params, headers=HEADERS, timeout=15)
        sr.raise_for_status()

        soup = BeautifulSoup(sr.text, "html.parser")

        # 1) ê°€ì¥ ì•ˆì •ì ì¸ ì¹´ë“œ íƒ€ì´í‹€ ë§í¬ (a.bo3)
        link_tag = soup.select_one("a.bo3")
        item_url = None
        if link_tag and link_tag.get("href"):
            item_url = urllib.parse.urljoin("https://www.aladin.co.kr", link_tag["href"])

        # 2) ë°±ì—…: ì •ê·œì‹ìœ¼ë¡œ wproduct ë§í¬ ì¡ê¸°(ìŒ/í™‘ë”°ì˜´í‘œ ëª¨ë‘)
        if not item_url:
            m = re.search(r'href=[\'\"](/shop/wproduct\.aspx\?ItemId=\d+[^\'\"]*)[\'\"]', sr.text, re.I)
            if m:
                item_url = urllib.parse.urljoin("https://www.aladin.co.kr", html.unescape(m.group(1)))

        # 3) ê·¸ë˜ë„ ì—†ìœ¼ë©´, ì²« ìƒí’ˆ ì¹´ë“œ ë‚´ ë‹¤ë¥¸ ë§í¬ ì‹œë„
        if not item_url:
            first_card = soup.select_one(".ss_book_box, .ss_book_list")
            if first_card:
                a = first_card.find("a", href=True)
                if a:
                    item_url = urllib.parse.urljoin("https://www.aladin.co.kr", a["href"])

...

        # ìƒí’ˆ ì •ë³´ í‘œì—ì„œ í‚¤ì›Œë“œë¡œ ì¶”ì¶œ ì‹œë„
        info_box = psoup.select_one("#Ere_prod_allwrap, #Ere_prod_mconts_wrap, #Ere_prod_titlewrap")
        if info_box:
            text = clean_text(info_box.get_text(" "))
            # ì•„ì£¼ ëŠìŠ¨í•œ íŒ¨í„´(ìˆì„ ë•Œë§Œ ì¡í˜)
            m_author = re.search(r"(ì €ì|ì§€ì€ì´)\s*:\s*([^\|Â·/]+)", text)
            m_publisher = re.search(r"(ì¶œíŒì‚¬)\s*:\s*([^\|Â·/]+)", text)
            m_pubdate = re.search(r"(ì¶œê°„ì¼|ì¶œíŒì¼)\s*:\s*([0-9]{4}\.[0-9]{1,2}\.[0-9]{1,2})", text)
            if m_author:   author   = clean_text(m_author.group(2))
            if m_publisher: publisher = clean_text(m_publisher.group(2))
            if m_pubdate:  pub_date = clean_text(m_pubdate.group(2))

        # ì¹´í…Œê³ ë¦¬(ë¹µë¶€ìŠ¤ëŸ¬ê¸°) ì‹œë„
        crumbs = psoup.select(".location, .path, .breadcrumb")
        if crumbs:
            cat_text = clean_text(" > ".join(c.get_text(" ") for c in crumbs))

        # ë””ë²„ê·¸: ì–´ëŠ ë§í¬ë¡œ ë“¤ì–´ê°”ëŠ”ì§€/íƒ€ì´í‹€ í™•ì¸
        with st.expander("ë””ë²„ê·¸: ìŠ¤í¬ë ˆì´í•‘ ì§„ì… URL / íŒŒì‹± ê²°ê³¼"):
            st.write({"item_url": item_url, "title": title})
        
        return BookInfo(
            title=title,
            description=description,
            isbn13=isbn13,
            author=author,
            publisher=publisher,
            pub_date=pub_date,
            category=cat_text
        )
    except Exception as e:
        st.error(f"ì›¹ ìŠ¤í¬ë ˆì´í•‘ ì˜ˆì™¸: {e}")
        return None


# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3) ì±—Gì—ê²Œ 'KDC ìˆ«ìë§Œ' ìš”ì²­ â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ask_llm_for_kdc(book: BookInfo, api_key: str, model: str = DEFAULT_MODEL, anchor_ryu: Optional[str] = None) -> Optional[str]:
    if not api_key:
        raise RuntimeError("OPENAI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°” ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì…ë ¥í•˜ì„¸ìš”.")

    anchor_rule = ""
    if anchor_ryu and anchor_ryu.isdigit() and len(anchor_ryu) == 1:
        anchor_rule = (
            f"\nì¶”ê°€ ì¡°ê±´: ìµœì¢… ë¶„ë¥˜ê¸°í˜¸ì˜ ë°±ìœ„(ì²« ìë¦¬)ëŠ” ë°˜ë“œì‹œ '{anchor_ryu}'ë¡œ ì‹œì‘í•´ì•¼ í•œë‹¤. "
            f"ë‹¤ë¥¸ ìˆ«ìë¡œ ì‹œì‘í•˜ë©´ ì•ˆ ëœë‹¤."
        )

    sys_prompt = (
        "ë„ˆëŠ” í•œêµ­ ì‹­ì§„ë¶„ë¥˜(KDC) ì „ë¬¸ê°€ë‹¤. "
        "ì•„ë˜ ë„ì„œ ì •ë³´ë¥¼ ë³´ê³  KDC ë¶„ë¥˜ê¸°í˜¸ë¥¼ 'ìˆ«ìë§Œ' ì¶œë ¥í•´ë¼. "
        "í˜•ì‹ ì˜ˆì‹œ: 813.7 / 325.1 / 005 / 181 ë“±. "
        "ì„¤ëª…, ì ‘ë‘/ì ‘ë¯¸ í…ìŠ¤íŠ¸, ê¸°íƒ€ ë¬¸ìëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆë¼."
        + anchor_rule
    )
    payload = {
        "title": book.title,
        "author": book.author,
        "publisher": book.publisher,
        "pub_date": book.pub_date,
        "isbn13": book.isbn13,
        "category": book.category,
        "description": book.description,
        "toc": book.toc,
    }
    user_prompt = (
        "ë„ì„œ ì •ë³´(JSON):\n"
        f"{json.dumps(payload, ensure_ascii=False, indent=2)}\n\n"
        "KDC ìˆ«ìë§Œ ì¶œë ¥:"
    )

    try:
        resp = requests.post(
            OPENAI_CHAT_COMPLETIONS,
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
            },
            json={
                "model": model,
                "messages": [
                    {"role": "system", "content": sys_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                "temperature": 0.0,
                "max_tokens": 8,
            },
            timeout=30,
        )
        resp.raise_for_status()
        data = resp.json()
        text = (data.get("choices",[{}])[0].get("message",{}).get("content","") or "").strip()
        normalized = first_match_number(text)
        if not normalized:
            return None
        # ì‚¬í›„ ë³´ì •: ç™¾ä½ ì•µì»¤ ê°•ì œ
        return enforce_anchor_ryu(normalized, anchor_ryu)
    except Exception as e:
        st.error(f"LLM í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4) íŒŒì´í”„ë¼ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_kdc_from_isbn(isbn13: str, ttbkey: Optional[str], openai_key: str, model: str) -> Optional[str]:
    info = aladin_lookup_by_api(isbn13, ttbkey) if ttbkey else None
    if not info:
        info = aladin_lookup_by_web(isbn13)
    if not info:
        st.warning("ì•Œë¼ë”˜ì—ì„œ ë„ì„œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None
    NLK_KEY = _get_secret('api_keys','nlk_key', default='') or os.getenv('NLK_OPEN_API_KEY')
    ea3 = nlk_fetch_ea_add_code(isbn13, NLK_KEY)
    anchor_ryu = ea3[0] if ea3 and len(ea3)==3 else None
    code = ask_llm_for_kdc(info, api_key=openai_key, model=model, anchor_ryu=anchor_ryu)
    # ë””ë²„ê·¸ìš©: ì–´ë–¤ ì •ë³´ë¥¼ ë„˜ê²¼ëŠ”ì§€ ë³´ì—¬ì£¼ê¸°(ê°œì¸ì •ë³´ ì—†ìŒ)
    with st.expander("LLM ì…ë ¥ ì •ë³´(í™•ì¸ìš©)"):
        st.json({
            "title": info.title,
            "author": info.author,
            "publisher": info.publisher,
            "pub_date": info.pub_date,
            "isbn13": info.isbn13,
            "anchor_ryu_from_EA3": (ea3[0] if ("ea3" in locals() and ea3) else None),
            "category": info.category,
        })
    return code

...
            code = get_kdc_from_isbn(
                isbn13=isbn,
                ttbkey=ALADIN_TTBKEY,
                openai_key=OPENAI_API_KEY,
                model=MODEL,
            )

        st.subheader("ê²°ê³¼")
        if code:
            st.markdown(f"### âœ… ì¶”ì²œ KDC: **`{code}`**")
            st.caption("â€» ìˆ«ìë§Œ ë°˜í™˜í•˜ë„ë¡ ê°•ì œí–ˆìœ¼ë©°, ì†Œìˆ˜ì  ì´í•˜ ì„¸ë¶„ì€ ëª¨ë¸ íŒë‹¨ì— ë”°ë¼ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.error("ë¶„ë¥˜ê¸°í˜¸ ì¶”ì²œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ISBN/í‚¤ë¥¼ í™•ì¸í•˜ê±°ë‚˜, ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
