# new056_with_EA_ADD_CODE.py (Streamlit ì „ìš© + NLK ì¬ì‹œë„/íƒ€ì„ì•„ì›ƒ/ìºì‹œ ë°˜ì˜)
# - ê¸°ì¡´ UI/íë¦„ ìœ ì§€: ì•Œë¼ë”˜ APIâ†’(ì‹¤íŒ¨ ì‹œ) ì›¹ ë³´ì™„â†’NLK EA_ADD_CODEë¡œ ë°±ìœ„(ë¥˜) ì•µì»¤â†’LLM ë¶„ë¥˜
# - NLK ì‹¤íŒ¨ ì‹œ: ì—ëŸ¬ ì•Œë¦¼ 1íšŒ + ì•µì»¤ ì—†ì´ LLMë§Œìœ¼ë¡œ ê³„ì† ì§„í–‰(ì‚¬ìš©ì í•©ì˜ ë°˜ì˜)

import os
import re
import json
import html
import urllib.parse
from dataclasses import dataclass
from typing import Optional, Dict, Any

import requests
import streamlit as st
from bs4 import BeautifulSoup

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìƒìˆ˜/ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_MODEL = "gpt-4o-mini"
ALADIN_LOOKUP_URL = "https://www.aladin.co.kr/ttb/api/ItemLookUp.aspx"
ALADIN_SEARCH_URL = "https://www.aladin.co.kr/search/wsearchresult.aspx"
OPENAI_CHAT_COMPLETIONS = "https://api.openai.com/v1/chat/completions"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (compatible; KDCFetcher/1.0; +https://example.local)"
}

# (ì„ íƒ) í™˜ê²½ì„¤ì • ë””ë²„ê·¸
with st.expander("í™˜ê²½ì„¤ì • ë””ë²„ê·¸", expanded=False):
    from pathlib import Path
    st.write("ğŸ“ ì•± í´ë”:", Path(__file__).resolve().parent.as_posix())
    st.write("ğŸ” secrets.toml ì¡´ì¬?:", (Path(__file__).resolve().parent / ".streamlit" / "secrets.toml").exists())
    st.write("ğŸ”‘ st.secrets í‚¤ë“¤:", list(st.secrets.keys()))
    st.write("api_keys ë‚´ìš©:", dict(st.secrets.get("api_keys", {})))
    st.write("âœ… openai_key ë¡œë“œë¨?:", bool(st.secrets.get("api_keys", {}).get("openai_key")))
    st.write("âœ… aladin_key ë¡œë“œë¨?:", bool(st.secrets.get("api_keys", {}).get("aladin_key")))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ secrets.toml ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ fallback â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _get_secret(*path, default: str = "") -> str:
    try:
        v = st.secrets
        for p in path:
            v = v[p]
        return v if isinstance(v, str) else default
    except Exception:
        return default

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°ì´í„° í´ë˜ìŠ¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@dataclass
class BookInfo:
    title: str = ""
    author: str = ""
    pub_date: str = ""
    publisher: str = ""
    isbn13: str = ""
    category: str = ""
    description: str = ""
    toc: str = ""
    extra: Dict[str, Any] = None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€
def clean_text(s: Optional[str]) -> str:
    if not s:
        return ""
    s = html.unescape(s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

def first_match_number(text: str) -> Optional[str]:
    """KDC ìˆ«ìë§Œ ì¶”ì¶œ: 0~999 ë˜ëŠ” ì†Œìˆ˜ì  í¬í•¨(ì˜ˆ: 813.7)"""
    if not text:
        return None
    m = re.search(r"\b([0-9]{1,3}(?:\.[0-9]+)?)\b", text)
    return m.group(1) if m else None

def first_or_empty(lst):
    return lst[0] if lst else ""

def strip_tags(html_text: str) -> str:
    return re.sub(r"<[^>]+>", " ", html_text or "")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# NLK(Open API) â€” EA_ADD_CODE ì¡°íšŒ (ì¬ì‹œë„/íƒ€ì„ì•„ì›ƒ + ìºì‹œ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_NLK_EA_CACHE: Dict[str, Optional[str]] = {}

def nlk_fetch_ea_add_code(isbn13: str, api_key: Optional[str]) -> Optional[str]:
    """
    NLK Open API ì¼ë°˜ê²€ìƒ‰ìœ¼ë¡œ ISBNì„ ì¡°íšŒí•˜ì—¬ EA_ADD_CODEë¥¼ ì–»ëŠ”ë‹¤.
    ë°˜í™˜: 'ë’¤ 3ìë¦¬' ë¶„ë¥˜ì½”ë“œ(ì˜ˆ: '813') ë˜ëŠ” None
    - NLK_RETRIES (ê¸°ë³¸ 2), NLK_CONNECT_TIMEOUT(ê¸°ë³¸ 3), NLK_READ_TIMEOUT(ê¸°ë³¸ 5) í™˜ê²½ë³€ìˆ˜ë¡œ ì¡°ì ˆ ê°€ëŠ¥
    """
    if not api_key:
        return None
    if isbn13 in _NLK_EA_CACHE:
        return _NLK_EA_CACHE[isbn13]

    url = "https://www.nl.go.kr/NL/search/openApi/search.do"
    params = {
        "key": api_key,
        "srchTarget": "total",
        "kwd": isbn13,
        "pageNum": 1,
        "pageSize": 1,
        "apiType": "json",
    }

    tries = int(os.getenv("NLK_RETRIES", "2"))
    connect_to = float(os.getenv("NLK_CONNECT_TIMEOUT", "3"))
    read_to = float(os.getenv("NLK_READ_TIMEOUT", "5"))

    last_err: Optional[Exception] = None
    for attempt in range(1, tries + 1):
        try:
            r = requests.get(url, params=params, timeout=(connect_to, read_to))
            r.raise_for_status()
            ctype = (r.headers.get("Content-Type") or "").lower()
            data = r.json() if "json" in ctype else {}

            # ê²°ê³¼ êµ¬ì¡° ê´€ìš© íƒìƒ‰
            item = None
            if isinstance(data, dict):
                for cand in ("result", "RESULT", "item", "ITEM", "docs", "DOCS", "channel", "CHANNEL"):
                    v = data.get(cand)
                    if isinstance(v, list) and v:
                        item = v[0]
                        break
                    if isinstance(v, dict) and v:
                        item = v
                        break
            if not item:
                _NLK_EA_CACHE[isbn13] = None
                return None

            # EA_ADD_CODE í›„ë³´ í‚¤
            ea_val = None
            for k in ("ea_add_code", "EA_ADD_CODE", "eaAddCode", "EA_ADDCD", "EA_ADD"):
                if k in item:
                    ea_val = str(item[k])
                    break
            if not ea_val:
                _NLK_EA_CACHE[isbn13] = None
                return None

            # ë’¤ 3ìë¦¬ë§Œ ì¶”ì¶œ
            m = re.search(r"(\d{3})\s*$", ea_val)
            ea3 = m.group(1) if m else None
            _NLK_EA_CACHE[isbn13] = ea3
            return ea3

        except (requests.exceptions.Timeout, requests.exceptions.ConnectTimeout) as e:
            last_err = e
            import time
            time.sleep(0.3 * attempt)
            continue
        except Exception as e:
            last_err = e
            break

    # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨: 1íšŒë§Œ ì•Œë¦¼ í›„ Noneìœ¼ë¡œ ì§„í–‰(ì•µì»¤ ì—†ì´ LLM)
    if last_err is not None:
        st.error(f"NLK SearchApi EA_ADD_CODE ì¡°íšŒ ì‹¤íŒ¨: {last_err}")
    _NLK_EA_CACHE[isbn13] = None
    return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ç™¾ä½(ë¥˜) ê°•ì œ ë³´ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€
def enforce_anchor_ryu(kdc: str, anchor: Optional[str]) -> str:
    """kdc('816.7') ë¬¸ìì—´ì—ì„œ ë°±ìœ„(ì²« ìë¦¬)ë¥¼ anchor('8')ë¡œ ê°•ì œ."""
    if not (kdc and anchor and anchor.isdigit() and len(anchor) == 1):
        return kdc
    norm = re.sub(r"\s+", "", kdc)
    m = re.match(r"(\d)(\d{2}(?:\.\d+)?)$", norm)
    if not m:
        m2 = re.match(r"(\d)(\d{0,2}(?:\.\d+)?)$", norm)
        if not m2:
            return kdc
        return anchor + m2.group(2)
    if m.group(1) == anchor:
        return kdc
    return anchor + m.group(2)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì•Œë¼ë”˜ API ì¡°íšŒ â†’ ì‹¤íŒ¨ ì‹œ ì›¹ ë³´ì™„
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def aladin_lookup_by_api(isbn13: str, ttbkey: str) -> Optional[BookInfo]:
    try:
        params = {
            "ttbkey": ttbkey,
            "itemIdType": "ISBN13",
            "ItemId": isbn13,
            "output": "JS",
            "Version": "20131101",
            "Cover": "Big",
        }
        r = requests.get(ALADIN_LOOKUP_URL, params=params, headers=HEADERS, timeout=12)
        r.raise_for_status()
        data = r.json()
        items = data.get("item", []) if isinstance(data, dict) else []
        if not items:
            return None
        it = items[0]
        title = clean_text(it.get("title"))
        author = clean_text(it.get("author"))
        publisher = clean_text(it.get("publisher"))
        pub_date = clean_text(it.get("pubDate"))
        desc = clean_text(strip_tags(it.get("description", "")))
        category = clean_text(it.get("categoryName", ""))
        toc = clean_text(strip_tags(it.get("fullDescription", "")))
        return BookInfo(
            title=title, author=author, publisher=publisher, pub_date=pub_date,
            isbn13=isbn13, description=desc, category=category, toc=toc
        )
    except Exception as e:
        st.info(f"ì•Œë¼ë”˜ API ì¡°íšŒ ì‹¤íŒ¨(ì›¹ ë³´ì¡° ì‹œë„): {e}")
        return None


def aladin_lookup_by_web(isbn13: str) -> Optional[BookInfo]:
    try:
        # ê²€ìƒ‰ URL (Book íƒ€ê²Ÿ ìš°ì„ )
        params = {"SearchTarget": "Book", "SearchWord": f"isbn:{isbn13}"}
        sr = requests.get(ALADIN_SEARCH_URL, params=params, headers=HEADERS, timeout=15)
        sr.raise_for_status()

        soup = BeautifulSoup(sr.text, "html.parser")

        # 1) ê°€ì¥ ì•ˆì •ì ì¸ ì¹´ë“œ íƒ€ì´í‹€ ë§í¬ (a.bo3)
        link_tag = soup.select_one("a.bo3")
        item_url = None
        if link_tag and link_tag.get("href"):
            item_url = urllib.parse.urljoin("https://www.aladin.co.kr", link_tag["href"])

        # 2) ë°±ì—…: ì •ê·œì‹ìœ¼ë¡œ wproduct ë§í¬ ì¡ê¸°(ìŒ/í™‘ë”°ì˜´í‘œ ëª¨ë‘)
        if not item_url:
            m = re.search(r'href=[\'\"](/shop/wproduct\.aspx\?ItemId=\d+[^\'\"]*)[\'\"]', sr.text, re.I)
            if m:
                item_url = urllib.parse.urljoin("https://www.aladin.co.kr", html.unescape(m.group(1)))

        # 3) ê·¸ë˜ë„ ì—†ìœ¼ë©´, ì²« ìƒí’ˆ ì¹´ë“œ ë‚´ ë‹¤ë¥¸ ë§í¬ ì‹œë„
        if not item_url:
            first_card = soup.select_one(".ss_book_box, .ss_book_list")
            if first_card:
                a = first_card.find("a", href=True)
                if a:
                    item_url = urllib.parse.urljoin("https://www.aladin.co.kr", a["href"])

        if not item_url:
            return None

        pr = requests.get(item_url, headers=HEADERS, timeout=15)
        pr.raise_for_status()
        psoup = BeautifulSoup(pr.text, "html.parser")

        title_tag = psoup.select_one("#Ere_prod_title_wrap h1, .Ere_prod_title h1, #Ere_prod_title h1")
        title = clean_text(title_tag.get_text(" ")) if title_tag else ""

        desc_tag = psoup.select_one("#Ere_prod_mconts .Ere_prod_mconts_L .conts_info")
        description = clean_text(strip_tags(desc_tag.decode_contents())) if desc_tag else ""

        author = publisher = pub_date = cat_text = ""
        info_box = psoup.select_one("#Ere_prod_allwrap, #Ere_prod_mconts_wrap, #Ere_prod_titlewrap")
        if info_box:
            text = clean_text(info_box.get_text(" "))
            # ì•„ì£¼ ëŠìŠ¨í•œ íŒ¨í„´(ìˆì„ ë•Œë§Œ ì¡í˜)
            m_author = re.search(r"(ì €ì|ì§€ì€ì´)\s*:\s*([^\|Â·/]+)", text)
            m_publisher = re.search(r"(ì¶œíŒì‚¬)\s*:\s*([^\|Â·/]+)", text)
            m_pubdate = re.search(r"(ì¶œê°„ì¼|ì¶œíŒì¼)\s*:\s*([0-9]{4}\.[0-9]{1,2}\.[0-9]{1,2})", text)
            if m_author:   author   = clean_text(m_author.group(2))
            if m_publisher: publisher = clean_text(m_publisher.group(2))
            if m_pubdate:  pub_date = clean_text(m_pubdate.group(2))

        # ì¹´í…Œê³ ë¦¬(ë¹µë¶€ìŠ¤ëŸ¬ê¸°) ì‹œë„
        crumbs = psoup.select(".location, .path, .breadcrumb")
        if crumbs:
            cat_text = clean_text(" > ".join(c.get_text(" ") for c in crumbs))

        # ë””ë²„ê·¸: ì–´ëŠ ë§í¬ë¡œ ë“¤ì–´ê°”ëŠ”ì§€/íƒ€ì´í‹€ í™•ì¸
        with st.expander("ë””ë²„ê·¸: ìŠ¤í¬ë ˆì´í•‘ ì§„ì… URL / íŒŒì‹± ê²°ê³¼"):
            st.write({"item_url": item_url, "title": title})
        
        return BookInfo(
            title=title,
            description=description,
            isbn13=isbn13,
            author=author,
            publisher=publisher,
            pub_date=pub_date,
            category=cat_text
        )
    except Exception as e:
        st.error(f"ì›¹ ìŠ¤í¬ë ˆì´í•‘ ì˜ˆì™¸: {e}")
        return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3) ì±—Gì—ê²Œ 'KDC ìˆ«ìë§Œ' ìš”ì²­ â”€â”€â”€â”€â”€â”€â”€â”€â”€
def ask_llm_for_kdc(book: BookInfo, api_key: str, model: str = DEFAULT_MODEL, anchor_ryu: Optional[str] = None) -> Optional[str]:
    if not api_key:
        raise RuntimeError("OPENAI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤. ì‚¬ì´ë“œë°” ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì…ë ¥í•˜ì„¸ìš”.")

    anchor_rule = ""
    if anchor_ryu and anchor_ryu.isdigit() and len(anchor_ryu) == 1:
        anchor_rule = (
            f"\nì¶”ê°€ ì¡°ê±´: ìµœì¢… ë¶„ë¥˜ê¸°í˜¸ì˜ ë°±ìœ„(ì²« ìë¦¬)ëŠ” ë°˜ë“œì‹œ '{anchor_ryu}'ë¡œ ì‹œì‘í•´ì•¼ í•œë‹¤. "
            f"ë‹¤ë¥¸ ìˆ«ìë¡œ ì‹œì‘í•˜ë©´ ì•ˆ ëœë‹¤."
        )

    sys_prompt = (
        "ë„ˆëŠ” í•œêµ­ ì‹­ì§„ë¶„ë¥˜(KDC) ì „ë¬¸ê°€ë‹¤. "
        "ì•„ë˜ ë„ì„œ ì •ë³´ë¥¼ ë³´ê³  KDC ë¶„ë¥˜ê¸°í˜¸ë¥¼ 'ìˆ«ìë§Œ' ì¶œë ¥í•´ë¼. "
        "í˜•ì‹ ì˜ˆì‹œ: 813.7 / 325.1 / 005 / 181 ë“±. "
        "ì„¤ëª…, ì ‘ë‘/ì ‘ë¯¸ í…ìŠ¤íŠ¸, ê¸°íƒ€ ë¬¸ìëŠ” ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆë¼."
        + anchor_rule
    )
    payload = {
        "title": book.title,
        "author": book.author,
        "publisher": book.publisher,
        "pub_date": book.pub_date,
        "isbn13": book.isbn13,
        "category": book.category,
        "description": book.description,
        "toc": book.toc,
    }
    user_prompt = (
        "ë„ì„œ ì •ë³´(JSON):\n"
        f"{json.dumps(payload, ensure_ascii=False, indent=2)}\n\n"
        "KDC ìˆ«ìë§Œ ì¶œë ¥:"
    )

    try:
        resp = requests.post(
            OPENAI_CHAT_COMPLETIONS,
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
            },
            json={
                "model": model,
                "messages": [
                    {"role": "system", "content": sys_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                "temperature": 0.0,
                "max_tokens": 8,
            },
            timeout=30,
        )
        resp.raise_for_status()
        data = resp.json()
        text = (data.get("choices",[{}])[0].get("message",{}).get("content","") or "").strip()
        normalized = first_match_number(text)
        if not normalized:
            return None
        # ì‚¬í›„ ë³´ì •: ç™¾ä½ ì•µì»¤ ê°•ì œ
        return enforce_anchor_ryu(normalized, anchor_ryu)
    except Exception as e:
        st.error(f"LLM í˜¸ì¶œ ì˜¤ë¥˜: {e}")
        return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4) íŒŒì´í”„ë¼ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_kdc_from_isbn(isbn13: str, ttbkey: Optional[str], openai_key: str, model: str) -> Optional[str]:
    info = aladin_lookup_by_api(isbn13, ttbkey) if ttbkey else None
    if not info:
        info = aladin_lookup_by_web(isbn13)
    if not info:
        st.warning("ì•Œë¼ë”˜ì—ì„œ ë„ì„œ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return None

    # NLK EA_ADD_CODE â†’ ë°±ìœ„ ì•µì»¤(ì‹¤íŒ¨ ì‹œ None, ì•µì»¤ ì—†ì´ ì§„í–‰)
    NLK_KEY = _get_secret('api_keys','nlk_key', default='') or os.getenv('NLK_OPEN_API_KEY')
    ea3 = nlk_fetch_ea_add_code(isbn13, NLK_KEY)
    anchor_ryu = ea3[0] if ea3 and len(ea3) == 3 else None

    code = ask_llm_for_kdc(info, api_key=openai_key, model=model, anchor_ryu=anchor_ryu)

    with st.expander("LLM ì…ë ¥ ì •ë³´(í™•ì¸ìš©)"):
        st.json({
            "title": info.title,
            "author": info.author,
            "publisher": info.publisher,
            "pub_date": info.pub_date,
            "isbn13": info.isbn13,
            "category": info.category,
            "anchor_ryu_from_EA3": anchor_ryu,
        })
    return code

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5) Streamlit UI (ê¸°ì¡´ ìœ ì§€) â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="KDC ë¶„ë¥˜ ì¶”ì²œ", page_icon="ğŸ“š", layout="centered")
st.title("KDC ë¶„ë¥˜ ì¶”ì²œ (EA_ADD_CODEë¡œ ë°±ìœ„ ê³ ì •)")

with st.sidebar:
    st.header("API í‚¤")
    default_openai = _get_secret('api_keys','openai_key', default=os.getenv("OPENAI_API_KEY",""))
    default_aladin = _get_secret('api_keys','aladin_key', default=os.getenv("ALADIN_TTB_KEY",""))
    default_nlk    = _get_secret('api_keys','nlk_key', default=os.getenv("NLK_OPEN_API_KEY",""))

    OPENAI_API_KEY = st.text_input("OpenAI API Key", value=default_openai, type="password")
    ALADIN_TTBKEY  = st.text_input("ì•Œë¼ë”˜ TTB Key", value=default_aladin, type="password")
    _ = st.text_input("NLK Open API Key", value=default_nlk, type="password")
    st.caption("â€» ì…ë ¥ ë¹„ì›Œë‘ë©´ secrets/í™˜ê²½ë³€ìˆ˜ ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

col1, col2 = st.columns([3,1])
with col1:
    isbn = st.text_input("ISBN-13", placeholder="ì˜ˆ: 9791162542329")
with col2:
    MODEL = st.text_input("Model", value=DEFAULT_MODEL)

run = st.button("ë¶„ë¥˜ ì¶”ì²œ")

if run:
    if not isbn or not re.match(r"^97[89]\d{10}$", isbn):
        st.error("ìœ íš¨í•œ ISBN-13ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 979ë¡œ ì‹œì‘, ì´ 13ìë¦¬).")
    else:
        code = get_kdc_from_isbn(
            isbn13=isbn,
            ttbkey=(ALADIN_TTBKEY or _get_secret('api_keys','aladin_key', default=os.getenv("ALADIN_TTB_KEY",""))),
            openai_key=(OPENAI_API_KEY or _get_secret('api_keys','openai_key', default=os.getenv("OPENAI_API_KEY",""))),
            model=MODEL,
        )

        st.subheader("ê²°ê³¼")
        if code:
            st.markdown(f"### âœ… ì¶”ì²œ KDC: **`{code}`**")
            st.caption("â€» ìˆ«ìë§Œ ë°˜í™˜í•˜ë„ë¡ ê°•ì œí–ˆìœ¼ë©°, ì†Œìˆ˜ì  ì´í•˜ ì„¸ë¶„ì€ ëª¨ë¸ íŒë‹¨ì— ë”°ë¼ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            st.error("ë¶„ë¥˜ê¸°í˜¸ ì¶”ì²œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ISBN/í‚¤ë¥¼ í™•ì¸í•˜ê±°ë‚˜, ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6) (ì„ íƒ) ê°„ë‹¨ í…ŒìŠ¤íŠ¸: ìŠ¤í¬ë¦½íŠ¸ë¡œ ì‹¤í–‰ ì‹œë§Œ ë™ì‘ â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Streamlit ëŸ°íƒ€ì„ì—ì„œëŠ” ì‹¤í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
if __name__ == "__main__":
    def _run_tests():
        # enforce_anchor_ryu
        assert enforce_anchor_ryu("816.7", "8") == "816.7"
        assert enforce_anchor_ryu("316.4", "8") == "816.4"
        assert enforce_anchor_ryu("005", "0") == "005"
        assert enforce_anchor_ryu("813", "8") == "813"
        assert enforce_anchor_ryu("813.7", None) == "813.7"
        # first_match_number
        assert first_match_number("ì¶”ì²œ 813.7 ì…ë‹ˆë‹¤") == "813.7"
        assert first_match_number("ì½”ë“œëŠ” 325 ì…ë‹ˆë‹¤") == "325"
        assert first_match_number("") is None
        print("âœ… ê°„ë‹¨ í…ŒìŠ¤íŠ¸ í†µê³¼")
    _run_tests()
